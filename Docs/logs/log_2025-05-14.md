# 🛠️ Daily Progress Log — 2025-05-14

## 👥 Team Members Present
- [x] Arun  
- [x] Domínguez  
- [x] Souto  
- [x] Chen  

## 🎯 What We Did Today
1. Upgraded the robot by replacing the old motors with more powerful ones for better torque and climbing ability.  
2. Added new components to enhance the robot’s performance and stability.  
3. Presented our current progress to the professor and received feedback.  
4. Started working on the **software side**, focusing on setting up the **visual SLAM** system.

## 💡 Decisions Made

| Topic               | Decision                                                                      | Why                                                                                   |
|---------------------|-------------------------------------------------------------------------------|---------------------------------------------------------------------------------------|
| Motor upgrade       | Swapped in more powerful motors                                              | Original motors lacked sufficient torque; new ones improve movement and stair climbing |
| Software focus      | Begin implementing visual SLAM pipeline                                      | Essential for robot localization and 3D environment mapping                            |
| Feedback integration| Follow professor’s suggestions to improve mechanical and software integration | Helps align project direction with expectations and address identified weaknesses      |

## 🧪 What We Tested
- Checked the fit and performance of the new motors under load.  
- Verified basic connectivity between Raspberry Pi and sensors after hardware upgrade.  
- Ran initial visual SLAM software tests to check camera input and feature tracking.

## 🔧 Problems Faced
- Needed to recalibrate the chassis and mounts to accommodate the larger motors.  
- Initial SLAM tests showed noisy or unstable localization due to unoptimized parameters.

## 📌 Next Steps
1. Fine-tune motor control and verify smooth movement with the upgraded motors.  
2. Continue developing the visual SLAM pipeline and adjust parameters for better accuracy.  
3. Integrate SLAM outputs with motor commands to enable basic autonomous navigation.  
4. Prepare a demo for next session to show combined hardware + software progress.  
